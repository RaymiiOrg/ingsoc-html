
    <!DOCTYPE html>
    <html lang="en">
        <head>
        <title>Wallbase.cc commandline bash wget downloader - Raymii.org</title>
        <!-- <link href="/s/inc/css/custom-first.css" rel="stylesheet" />-->
        <link href="/s/inc/css/marx.css" rel="stylesheet"  />
        <!-- <link href="/s/inc/css/custom.css" rel="stylesheet" title="custom" />-->
        <script src="/s//inc/js/instant.js" type="text/javascript"></script> 
        <script src="/s//inc/js/toc.js" type="text/javascript"></script> 
        <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link type="application/opensearchdescription+xml" rel="search" href="/s/inc/opensearch.xml"/>
        <link rel="alternate" type="application/rss+xml" title="RSS Feed for Raymii.org" href="https://raymii.org/s/feed.xml" />
    </head>
    <body>
        
        <a id="top-of-page"></a>
        <main>
        <a class="skip-main" href="#main">Skip to main content</a>
            <header>
                <h1 class="headheader">
                    <a href="https://raymii.org/s/">Raymii.org <img src="/s/inc/img/resistor-50.png"></a>
                </h1>
                <small>
                  Quis custodiet ipsos custodes?<br>
                  <a href="/s/">Home</a> | 
                  <a href="/s/tags/all.html">All pages</a> | 
                  <a href="https://raymii.org/s/feed.xml">RSS Feed</a> | 
                  <a href="gopher://raymii.org:70">Gopher</a>
                </small>
            </header>
          

    <h2 class='headheader' id='main'>Wallbase.cc commandline bash wget downloader</h2><p><small>Published: 22-07-2012 | Author: Remy van Elst | <a href="Wallbase.cc_Command_line_script.txt" class="link">Text only version of this article</small></a></p><div class='ad'>
                            <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
                            <!-- voorartikel -->
                            <ins class="adsbygoogle"
                                 style="display:inline-block;width:728px;height:90px"
                                 data-ad-client="ca-pub-7993642564731324"
                                 data-ad-slot="6172324376"></ins>
                            <script>
                            (adsbygoogle = window.adsbygoogle || []).push({});
                            </script>
                        </div><br><div id="toc"><h3>Table of Contents</h3></div><hr><div id="contents"><p>I mostly get my wallpapers from the website <a href="http://wallbase.cc">Wallbase.cc</a>. But the site
requires a lot of javascript and ajax, and it is hard to get a lot of wallpapers
at once. I&#39;ve written a script for this problem, it lets you grep wallbase from
the cli!</p>

<p><a href="https://www.digitalocean.com/?refcode=7435ae6b8212">If you like this article, consider sponsoring me by trying out a Digital Ocean
VPS. With this link you&#39;ll get $100 credit for 60 days). (referral link)</a></p>

<h5>Features</h5>

<ul>
<li>Bash, wget, awk only, nothing else required (well, active internet connection)</li>
<li>Get the newest wallpapers from wallbase.cc</li>
<li>Search for a term and get all the wallpapers from the first page at wallbase.cc</li>
<li>Get random wallpapers</li>
<li>Duplicate check, removes duplicate wallpapers (filesize &amp;&amp; md5sum)</li>
</ul>

<h5>Usage</h5>

<p>Very simple, first copy and paste the script into a file (wall.sh) and chmod
that so that you can execute it. chmod +x ./wall.sh ./wall.sh r for random
./wall.sh n for newest ./wall.sh s TERM for search TERM.</p>

<p>So to download forest wallpapers: ./wall.sh s forest</p>

<p>If you want to get a lot of random wallpapers then execute this: while true; do
./wall.sh r; sleep 1; done and kill that afet 10 minutes...</p>

<h5>The Script</h5>

<pre><code>#!/bin/bash
#Copyright (c) 2012 Remy van Elst
#Permission is hereby granted, free of charge, to any person obtaining a copy
#of this software and associated documentation files (the &quot;Software&quot;), to deal
#in the Software without restriction, including without limitation the rights
#to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#copies of the Software, and to permit persons to whom the Software is
#furnished to do so, subject to the following conditions:
#
#The above copyright notice and this permission notice shall be included in
#all copies or substantial portions of the Software.
#
#THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
#THE SOFTWARE.
#first the vars
BASEURL=&quot;http://wallbase.cc/search/&quot;
MODE=&quot;$1&quot;
SEARCH=&quot;$2&quot;
NEWWALLURL=&quot;http://wallbase.cc/search/0/0/213/eqeq/0x0/0/1/1/0/60/relevance/desc/wallpapers&quot;
WALLR=&quot;http://wallbase.cc/random/&quot;
CONFIGS=&quot;/0/213/eqeq/0x0/0/1/1/0/60/relevance/desc/wallpapers&quot;

#now see what we need to do
case &quot;$1&quot; in
   s)
   if [ -e $2 ]; then
      echo &quot;I need search terms&quot;
      exit 1
   fi
   GETURL=&quot;$BASEURL$SEARCH$CONFIGS&quot;
   ;;
   n)
   GETURL=&quot;$NEWWALLURL&quot;
   ;;
   r)
   GETURL=&quot;$WALLR&quot;
   ;;
   *)
   echo -e &quot;Usage:n$0 r for randomn$0 n for newestn$0 s TERM for search TERM.&quot;
   exit 1
   ;;
esac

GETURL=$WALLR
#get the wallpaper overview page, grep the wallpaper page urls and dump them into a file for wget
wget -q --referer=&quot;http://www.google.com&quot; --user-agent=&quot;Mozilla/5.0 (Windows NT 6.1; rv:12.0) Gecko/20120403211507 Firefox/12.0&quot; $GETURL -O- | egrep -o &quot;http://[^[:space:]]*&quot; | grep &quot;/wallpaper/&quot; | sed &#39;s/&quot;//g&#39; &gt; ./wallist

#put the url file in a variable, but first backup IFS and later restore it.
OLDIFS=$IFS
IFS=&#39;
&#39;
urlsa=( $( &lt; ./wallist ) )
IFS=$OLDIFS

#now loop trough the urls and wget the page, then grep the wallpaper URL, and then wget the wallpaper
for i in &quot;${urlsa[@]}&quot;
do
  echo $i
  wget -vv --referer=&quot;http://www.google.com&quot; --user-agent=&quot;Mozilla/5.0 (Windows NT 6.1; rv:12.0) Gecko/20120403211507 Firefox/12.0&quot; $i -O- | wget -vv -nd -nc `egrep -o &quot;http://[^[:space:]]*.jpg&quot;`
done

#now a duplicate check...
find -not -empty -type f -printf &quot;%sn&quot; | sort -rn | uniq -d | xargs -I{} -n1 find -type f -size {}c -print0 | xargs -0 md5sum | sort | uniq -w32 | cut -d&quot; &quot; -f3 | xargs -P 10 -r -n 1 rm
</code></pre>

<h5>Notes</h5>

<p>If you have any tips, questions or comments, please use the form below.<br>
<strong>Don&#39;t go and hammer the wallbase.cc servers, use this script responsibly</strong></p>
Tags: <a href="../tags/bash.html" class="link">bash</a>, <a href="../tags/command-line.html" class="link">command-line</a>, <a href="../tags/software.html" class="link">software</a>, <a href="../tags/wallbase.html" class="link">wallbase</a>, <a href="../tags/wallbase.cc.html" class="link">wallbase.cc</a>, <a href="../tags/wallpapers.html" class="link">wallpapers</a>, <a href="../tags/wget.html" class="link">wget</a></div><br/><footer><br/>
                <form role="search" action="https://encrypted.google.com/search"
                style="min-width:250px;max-width:300px;">
                    <div class="form-group">
                      <input type="hidden" name="as_sitesearch" value="raymii.org">
                      <input type="hidden" name="as_qdr" value="all">
                      <input type="text" name="as_q" class="form-control" placeholder="Search">
                    </div>
                  </form>
                <br>
                <p>Generated by <a href="/s/software/ingsoc.html">ingsoc</a> | 
                <a href="/s/software/Sparkling_Network.html">Cluster Status</a> | 
                <a href="/s/static/About.html">About</a><br />
            
    </footer>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-3704876-6"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-3704876-6');
    </script>
     
    </body>
    </html>
    